

#--------------------------------------------------------
#
#       Songdo student: modeling
#
#        SH Kim, TW Kim
#        2019-12-12
#
#--------------------------------------------------------


library(dplyr)
library(ggplot2)
library(data.table)
library(MASS)
library(glmnet)
library(randomForest)
library(gbm)
library(rpart)
library(boot)
library(ROCR)
library(gridExtra)
library(psych)
library(corrgram)


# set working directory

setwd("C:/Users/u/Dropbox/1_2_0_student_SK/student")
getwd()

df16join.all <- tbl_df(read.csv("df16join.all.csv"))


# datasets for 10-feature model
#  (1) satif_orgi 
#  (2) satif_comp

select <- dplyr::select    # designate select to dplyr's select

satif_orgi <- df16join.all %>% select(s2_Q2_3, s2_Q2_4, s2_Q3_2, s2_Q7_9, s2_Q7_11, s2_Q7_16, s2_Q9_3, 
                                      s2_Q10_1, s2_Q15_1, s2_Q16_4,s2_Q8_2)     

newname <- c("career", "timeManage", "transfer", "selfDirectedness", "interpersonal", "creativity",
             "satifGeneralEdu", "satifRcEdu", "alcohol", "depression", "overallSatif")

names(satif_orgi) <- newname  # new variable name
satif_comp <- satif_orgi %>% na.omit()


# correlation panel function

panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...){
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(0, 1, 0, 1))
  r <- abs(cor(x, y))
  txt <- format(c(r, 0.123456789), digits = digits)[1]
  txt <- paste0(prefix, txt)
  if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
  text(0.5, 0.5, txt, cex = cex.cor * r)
}


pairs(satif_comp %>% sample_n(min(1000, nrow(satif_comp))),
      lower.panel=function(x,y){ points(x,y); abline(0, 1, col='red')},
      upper.panel = panel.cor)
dev.off()


# set data

satif     <- satif_comp 

#  data split

set.seed(1606)
n <- nrow(satif)
idx <- 1:n
training_idx <- sample(idx, n*.60)     # training: 60%
idx <- setdiff(idx, training_idx)     
validate_idx <- sample(idx,n*.20)      # validation: 20%
test_idx<- setdiff(idx, validate_idx)  # test: 20%
training <- satif[training_idx,]
validation <- satif[validate_idx,]
test <- satif[test_idx,]



# linear regression
satif_lm_full <- lm(overallSatif ~ ., data = training)
summary(satif_lm_full)


# linear interaction
satif_lm_full2 <- lm(overallSatif~ .^2, data= training)
summary(satif_lm_full2)

# predict
predict(satif_lm_full, newdata=satif[1:5,])
predict(satif_lm_full2, newdata=satif[1:5,])

# Im - Step
satif_step <- stepAIC(satif_lm_full, 
                      scope = list(upper = ~ .^2, lower = ~1))
satif_step
anova(satif_step)
summary(satif_step)


# model estimate
rmse <- function(yi, yhat_i){
    sqrt(mean((yi - yhat_i)^2))
}

mae <- function(yi, yhat_i){
    mean(abs(yi - yhat_i))
}

y_obs <- validation$overallSatif
yhat_lm <- predict(satif_lm_full, newdata = validation)
yhat_lm_2 <- predict(satif_lm_full2, newdata   = validation)
yhat_step <- predict(satif_step, newdata= validation)
rmse(y_obs, yhat_lm)
rmse(y_obs, yhat_lm_2)
rmse(y_obs, yhat_step)


# Lasso

#xx <- model.matrix(overallSatif~.-1, satif)
#x <- xx[training_idx,]
x <- training[, -11]
y <- training$overallSatif

satif_cvfit <- cv.glmnet(x,y)
plot(satif_cvfit)
dev.off()
coef(satif_cvfit, s = c("lambda.1se"))
coef(satif_cvfit, s = c("lambda.min"))

(tmp <- coef(satif_cvfit, s = c("lambda.1se")))
tmp <- tmp[,1]
length(tmp[abs(tmp)>0])
(tmp <- coef(satif_cvfit, s = c("lambda.min")))
length(tmp[abs(tmp)>0])

#predict.cv.glmnet(satif_cvfit, s="lambda.min", newx = x[1:5,])

y_obs <- validation$overallSatif
yhat_glmnet <- predict(satif_cvfit, s="lambda.min", newx=xx[validate_idx,])
yhat_glmnet <- yhat_glmnet[,1] # change to a vector from [n*1] matrix
rmse(y_obs, yhat_glmnet)


# Decision trees

satif_tr <- rpart(overallSatif ~ ., data = training)
satif_tr

printcp(satif_tr)
summary(satif_tr)

opar <- par(mfrow = c(1,1), xpd = NA)
plot(satif_tr)
text(satif_tr, use.n = TRUE)
par(opar)
dev.off()

yhat_tr <- predict(satif_tr, validation)
rmse(y_obs, yhat_tr)


# Random forest

set.seed(1607)
satif_rf <- randomForest(overallSatif ~ ., training)
satif_rf


par(mfrow=c(1,2))
plot(satif_rf)
varImpPlot(satif_rf)
dev.off()

yhat_rf <- predict(satif_rf, newdata=validation)
rmse(y_obs, yhat_rf)


# Boosting

set.seed(1607)
satif_gbm <- gbm(overallSatif ~ ., data=training,
                n.trees=40000, cv.folds=3, verbose = TRUE)

(best_iter = gbm.perf(satif_gbm, method="cv"))
dev.off()

yhat_gbm <- predict(satif_gbm, n.trees=best_iter, newdata=validation)
rmse(y_obs, yhat_gbm)


# Final model selection with  test RMSE

data.frame(lm = rmse(y_obs, yhat_lm),
           glmnet = rmse(y_obs, yhat_glmnet),
           tr= rmse(y_obs, yhat_tr),
           rf = rmse(y_obs, yhat_rf),
           gbm = rmse(y_obs, yhat_gbm)) %>%
  reshape2::melt(value.name = 'rmse', variable.name = 'method')

rmse(test$overallSatif, predict(satif_lm_full, newdata = test))


# visualization of results

boxplot(list(lm = y_obs-yhat_lm,
             glmnet = y_obs-yhat_glmnet,
             tr = y_obs- yhat_tr,
             rf = y_obs-yhat_rf,
             gbm = y_obs-yhat_gbm), ylab="Error in Validation Set")
abline(h=0, lty=2, col='blue')
dev.off()


pairs(data.frame(y_obs=y_obs,
                 yhat_lm=yhat_lm,
                 yhat_glmnet=yhat_glmnet,
                 yhat_tr=yhat_tr,
                 yhat_rf=yhat_rf,
                 yhat_gbm=yhat_gbm),
      lower.panel=function(x,y){ points(x,y); abline(0, 1, col='red')},
      upper.panel = panel.cor)
dev.off()

